{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnqP/IWzWacDVFEZosm4/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuvad23/Deep-learning-with-PyTorch/blob/main/PyTorch_NN_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## üß† What is `torch.nn.Module`?\n",
        "\n",
        "In PyTorch, **`nn.Module`** is the **base class for all neural network components** ‚Äî layers, models, and even custom building blocks.\n",
        "\n",
        "Every neural network you define **inherits** from this class.\n",
        "\n",
        "Think of it as a blueprint that gives you:\n",
        "\n",
        "* A structure to define layers and parameters\n",
        "* A way to organize forward computations\n",
        "* Automatic tracking of trainable parameters\n",
        "* Easy integration with optimizers and loss functions\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Basic Structure\n",
        "\n",
        "Here‚Äôs what a minimal PyTorch model looks like:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()  # initialize base class\n",
        "        \n",
        "        # define layers\n",
        "        self.linear1 = nn.Linear(10, 20)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(20, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # define forward pass\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = MyModel()\n",
        "\n",
        "# Forward pass example\n",
        "input_data = torch.randn(5, 10)\n",
        "output = model(input_data)\n",
        "print(output.shape)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Key Components of `nn.Module`\n",
        "\n",
        "### 1. **`__init__()`**\n",
        "\n",
        "* You define **layers** and **submodules** here.\n",
        "* Layers like `nn.Linear`, `nn.Conv2d`, `nn.LSTM`, etc., automatically register their parameters.\n",
        "\n",
        "### 2. **`forward()`**\n",
        "\n",
        "* Defines **how the input passes** through the network.\n",
        "* This is where you describe your model‚Äôs logic.\n",
        "* You *don‚Äôt* call `forward()` directly ‚Äî you just do:\n",
        "\n",
        "  ```python\n",
        "  output = model(input)\n",
        "  ```\n",
        "\n",
        "  which internally calls `model.forward(input)`.\n",
        "\n",
        "### 3. **`parameters()`**\n",
        "\n",
        "* Returns an iterator over all **trainable parameters** (weights, biases).\n",
        "\n",
        "  ```python\n",
        "  for param in model.parameters():\n",
        "      print(param.shape)\n",
        "  ```\n",
        "\n",
        "### 4. **`named_parameters()`**\n",
        "\n",
        "* Same as above but also gives the **names** of each parameter.\n",
        "\n",
        "  ```python\n",
        "  for name, param in model.named_parameters():\n",
        "      print(name, param.shape)\n",
        "  ```\n",
        "\n",
        "### 5. **`state_dict()`**\n",
        "\n",
        "* Returns a Python dictionary containing all model parameters.\n",
        "\n",
        "  ```python\n",
        "  torch.save(model.state_dict(), \"model_weights.pth\")\n",
        "  ```\n",
        "* You can load it later using:\n",
        "\n",
        "  ```python\n",
        "  model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "  ```\n",
        "\n",
        "### 6. **`eval()` and `train()`**\n",
        "\n",
        "* `model.train()` ‚Üí enables dropout, batchnorm, etc. for training.\n",
        "* `model.eval()` ‚Üí disables dropout, batchnorm updates (used during testing/inference).\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ Example ‚Äî Custom Neural Network\n",
        "\n",
        "Let‚Äôs make a small neural network for regression:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RegressionNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RegressionNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Using the Model in Training\n",
        "\n",
        "```python\n",
        "model = RegressionNN(10, 32, 1)\n",
        "\n",
        "criterion = nn.MSELoss()          # Loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Optimizer\n",
        "\n",
        "for epoch in range(100):\n",
        "    inputs = torch.randn(5, 10)\n",
        "    targets = torch.randn(5, 1)\n",
        "\n",
        "    optimizer.zero_grad()         # Reset gradients\n",
        "    outputs = model(inputs)       # Forward pass\n",
        "    loss = criterion(outputs, targets)  # Compute loss\n",
        "    loss.backward()               # Backpropagation\n",
        "    optimizer.step()              # Update weights\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß± `nn.Module` Hierarchy ‚Äî Nested Modules\n",
        "\n",
        "You can have **modules inside modules**, like building blocks:\n",
        "\n",
        "```python\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(Block, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_dim, out_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class ComplexModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexModel, self).__init__()\n",
        "        self.block1 = Block(10, 20)\n",
        "        self.block2 = Block(20, 30)\n",
        "        self.output = nn.Linear(30, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        return self.output(x)\n",
        "```\n",
        "\n",
        "PyTorch automatically registers all nested submodules and parameters.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Useful Methods Summary\n",
        "\n",
        "| Method                 | Description                              |\n",
        "| ---------------------- | ---------------------------------------- |\n",
        "| `.parameters()`        | Returns all parameters (weights, biases) |\n",
        "| `.named_parameters()`  | Returns (name, parameter) pairs          |\n",
        "| `.children()`          | Returns direct submodules                |\n",
        "| `.modules()`           | Returns all nested submodules            |\n",
        "| `.state_dict()`        | Returns model‚Äôs state (weights, buffers) |\n",
        "| `.load_state_dict()`   | Loads model state                        |\n",
        "| `.to(device)`          | Moves model to CPU or GPU                |\n",
        "| `.train()` / `.eval()` | Sets training/inference mode             |\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Advantages of Using `nn.Module`\n",
        "\n",
        "‚úÖ Simplifies model definition\n",
        "‚úÖ Automatically registers layers and parameters\n",
        "‚úÖ Works seamlessly with autograd\n",
        "‚úÖ Integrates cleanly with optimizers\n",
        "‚úÖ Allows saving/loading of models easily\n",
        "‚úÖ Supports GPU/CPU switching with one line\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Summary Diagram\n",
        "\n",
        "```\n",
        "        +----------------------+\n",
        "        |    nn.Module         |\n",
        "        +----------+-----------+\n",
        "                   |\n",
        "        +----------v-----------+\n",
        "        | Your Custom Class     |\n",
        "        | (inherits nn.Module)  |\n",
        "        +----------+-----------+\n",
        "                   |\n",
        "          +--------v--------+\n",
        "          |  __init__()     |\n",
        "          |  forward()      |\n",
        "          +-----------------+\n",
        "                   |\n",
        "          +--------v--------+\n",
        "          | Model Object     |\n",
        "          | .parameters()    |\n",
        "          | .train()/.eval() |\n",
        "          | .state_dict()    |\n",
        "          +-----------------+\n",
        "```\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CqLZ1n3VBtNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smMdq8aX1bIa",
        "outputId": "1c08595d-aa53-40e7-af6c-9b1801e7b07e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5093],\n",
            "        [0.5601],\n",
            "        [0.5681],\n",
            "        [0.5144],\n",
            "        [0.5173]], grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ],
      "source": [
        "# ‚öôÔ∏è Basic Structure\n",
        "# Here‚Äôs what a minimal PyTorch model looks like:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# define class\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        #define layers\n",
        "        self.linear1 = nn.Linear(10,30)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(30,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # define forward pass\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# instantiate the model\n",
        "model = MyModel()\n",
        "\n",
        "# forward pass example\n",
        "input_data = torch.randn(5,10) # batch size of 5, input size of 10\n",
        "output = model(input_data)\n",
        "print(output)\n",
        "print(output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear1.weight"
      ],
      "metadata": {
        "id": "uF18hQ-OF-Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear1.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0oBqoweGFFX",
        "outputId": "71ae852a-443d-41a4-d7c8-6af931e26db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0415, -0.1561, -0.0629,  0.2592,  0.2734,  0.2189, -0.2004, -0.1361,\n",
              "        -0.1401,  0.0034,  0.1555,  0.0037, -0.0946,  0.2217, -0.0662,  0.1300,\n",
              "         0.1112,  0.0823, -0.2613, -0.2897, -0.3081,  0.2925, -0.1519,  0.0620,\n",
              "        -0.3029,  0.0196, -0.2717, -0.0968,  0.2977,  0.2388],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5c8V_HMGIfQ",
        "outputId": "9cf1f58a-faf2-47f2-9c11-948787fbe09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1808, -0.1670,  0.0623,  0.1002,  0.1004, -0.0437, -0.1101,  0.1174,\n",
              "          0.1531, -0.0341, -0.1300,  0.0074, -0.1106,  0.0968,  0.1296, -0.0861,\n",
              "          0.0352,  0.0741, -0.0855, -0.1740,  0.0778, -0.0329, -0.0609, -0.1046,\n",
              "          0.0457, -0.1098, -0.0706, -0.1547,  0.0016,  0.1140]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kuy1tBrGPwY",
        "outputId": "54c128c5-5a23-48cf-c270-aabf105fc1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.1308], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiC0VkNFGl1j",
        "outputId": "30473b67-70b3-434b-e669-2d2ad84eb278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(5,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rpIz79gGuoM",
        "outputId": "4bc80566-3005-40e3-9239-4acb099e7e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MyModel                                  [5, 1]                    --\n",
              "‚îú‚îÄLinear: 1-1                            [5, 30]                   330\n",
              "‚îú‚îÄReLU: 1-2                              [5, 30]                   --\n",
              "‚îú‚îÄLinear: 1-3                            [5, 1]                    31\n",
              "‚îú‚îÄSigmoid: 1-4                           [5, 1]                    --\n",
              "==========================================================================================\n",
              "Total params: 361\n",
              "Trainable params: 361\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another example\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyTestModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyTestModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(6,4)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(4,2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.linear3 = nn.Linear(2,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "model = MyTestModel()\n",
        "input_data = torch.randn(5,6)\n",
        "output = model(input_data)\n",
        "print(output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6JIYRXfItHR",
        "outputId": "7b987d2c-1ea9-403a-8391-ea3ad422b880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4977],\n",
            "        [0.5101],\n",
            "        [0.5093],\n",
            "        [0.5091],\n",
            "        [0.5098]], grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear1.weight #(linear one -(6*4) = 24 weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaoN37AkKL_0",
        "outputId": "1690a778-ebb9-4f88-8127-aba2704ed2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.3445,  0.2752,  0.3715, -0.1136,  0.3578, -0.3004],\n",
              "        [-0.2442,  0.2207,  0.2197,  0.2534, -0.0851,  0.0199],\n",
              "        [ 0.0486, -0.0233,  0.1396, -0.2920,  0.0227, -0.2233],\n",
              "        [ 0.0283, -0.1525, -0.0417,  0.3226, -0.3698,  0.0537]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.weight #(linear two -(4*2) = 8 weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1I5M-JuKnfe",
        "outputId": "f5d80179-ecc2-451f-c3c4-a7f8063dd830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.3356,  0.3246,  0.4793,  0.4041],\n",
              "        [-0.0530,  0.1229, -0.1731, -0.0078]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear3.weight #(linear three -(2*1) = 2 weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TkLK_hAKsqt",
        "outputId": "b6998a74-e2d6-46f5-dd50-6980abe9d0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1029, -0.0560]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear1.bias #(linear one -(4) = 4 bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K8rrm1vKxVu",
        "outputId": "9b46d0b9-c064-460a-e758-54219ebab215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0530,  0.2785, -0.0681,  0.1063], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.bias #(linear two -(2) = 2 bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AxMzaN6K3pz",
        "outputId": "abfbda15-96bc-414f-a89a-9e6fa2bf7421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.3893,  0.2026], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear3.bias #(linear three -(1) = 1 bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss9vpR2HK8GN",
        "outputId": "0ca6b76e-dd6f-4978-b50f-153ee75953fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.0512], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(5,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNA9esYWLCe5",
        "outputId": "ca618483-f4d2-4aed-da9a-f70c10f05b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MyTestModel                              [5, 1]                    --\n",
              "‚îú‚îÄLinear: 1-1                            [5, 4]                    28\n",
              "‚îú‚îÄReLU: 1-2                              [5, 4]                    --\n",
              "‚îú‚îÄLinear: 1-3                            [5, 2]                    10\n",
              "‚îú‚îÄReLU: 1-4                              [5, 2]                    --\n",
              "‚îú‚îÄLinear: 1-5                            [5, 1]                    3\n",
              "‚îú‚îÄSigmoid: 1-6                           [5, 1]                    --\n",
              "==========================================================================================\n",
              "Total params: 41\n",
              "Trainable params: 41\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using sequential\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(6,4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4,2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "model = Net()\n",
        "input_data = torch.randn(5,6)\n",
        "output = model(input_data)\n",
        "print(output)\n",
        "print(output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv2WnhfgPL1-",
        "outputId": "d132d709-2476-448c-9794-9acc4e56301c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5936],\n",
            "        [0.5936],\n",
            "        [0.5936],\n",
            "        [0.5936],\n",
            "        [0.5936]], grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† 1. Building a Neural Network using nn.Module:\n",
        "\n",
        "1Ô∏è‚É£ Define model using torch.nn.Module\n",
        "\n",
        "2Ô∏è‚É£ Use built-in activation functions\n",
        "\n",
        "3Ô∏è‚É£ Use built-in loss functions\n",
        "\n",
        "4Ô∏è‚É£ Use built-in optimizers"
      ],
      "metadata": {
        "id": "E71uj2z8UZlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ Full Working Example (Step-by-Step)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU() # built-in activation\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = 10\n",
        "hidden_size = 32\n",
        "output_size = 1\n",
        "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "\n",
        "\n",
        "# define the loss function (mean squred error)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# define the optimizer(adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Dummy training data\n",
        "input_data = torch.randn(100, 10)\n",
        "targets = torch.randn(100, 1)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # forward pass\n",
        "    outputs = model(input_data)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    # backward pass and optimization\n",
        "    optimizer.zero_grad() # clear old gradients\n",
        "    loss.backward() # compute gradients\n",
        "    optimizer.step() # update weights\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGETLIm3UQBG",
        "outputId": "1cb39ea7-6115-4b70-f97a-d91695e0cf3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.1533\n",
            "Epoch [20/100], Loss: 1.1028\n",
            "Epoch [30/100], Loss: 1.0607\n",
            "Epoch [40/100], Loss: 1.0228\n",
            "Epoch [50/100], Loss: 0.9881\n",
            "Epoch [60/100], Loss: 0.9555\n",
            "Epoch [70/100], Loss: 0.9244\n",
            "Epoch [80/100], Loss: 0.8944\n",
            "Epoch [90/100], Loss: 0.8662\n",
            "Epoch [100/100], Loss: 0.8390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                    | Description              | Example                                 |\n",
        "| ----------------------- | ------------------------ | --------------------------------------- |\n",
        "| 1Ô∏è‚É£ Build model         | Subclass `nn.Module`     | `class Net(nn.Module): ...`             |\n",
        "| 2Ô∏è‚É£ Activation function | Use built-in activations | `nn.ReLU()` / `torch.relu()`            |\n",
        "| 3Ô∏è‚É£ Loss function       | Built-in from `nn`       | `nn.MSELoss()`, `nn.CrossEntropyLoss()` |\n",
        "| 4Ô∏è‚É£ Optimizer           | From `torch.optim`       | `optim.Adam()`, `optim.SGD()`           |\n"
      ],
      "metadata": {
        "id": "ng3CtHOHXGEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† What is `torch.optim`?\n",
        "\n",
        "`torch.optim` is **PyTorch‚Äôs optimization package**.\n",
        "It provides implementations of **gradient-based optimization algorithms** like **SGD**, **Adam**, **RMSprop**, etc., that help minimize the loss function during training.\n",
        "\n",
        "In simple terms:\n",
        "\n",
        "> üîπ Your model computes predictions.\n",
        "> üîπ The loss function measures error.\n",
        "> üîπ `torch.optim` adjusts model parameters to reduce that error.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è The Training Loop Concept\n",
        "\n",
        "The training process using `torch.optim` always follows this pattern:\n",
        "\n",
        "```python\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()   # 1Ô∏è‚É£ Reset gradients\n",
        "    outputs = model(inputs) # 2Ô∏è‚É£ Forward pass\n",
        "    loss = criterion(outputs, targets)  # 3Ô∏è‚É£ Compute loss\n",
        "    loss.backward()         # 4Ô∏è‚É£ Backpropagation\n",
        "    optimizer.step()        # 5Ô∏è‚É£ Update parameters\n",
        "```\n",
        "\n",
        "Let‚Äôs explain this step-by-step üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Step-by-Step Breakdown\n",
        "\n",
        "### 1Ô∏è‚É£ `optimizer = torch.optim.OptimizerClass(parameters, lr=...)`\n",
        "\n",
        "* You first create an optimizer and tell it **which parameters** to update (usually the model‚Äôs parameters).\n",
        "* Example:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "```\n",
        "\n",
        "### 2Ô∏è‚É£ `optimizer.zero_grad()`\n",
        "\n",
        "* Clears old gradients (otherwise PyTorch *accumulates* them by default).\n",
        "* Always call this **before** `loss.backward()`.\n",
        "\n",
        "### 3Ô∏è‚É£ `loss.backward()`\n",
        "\n",
        "* Computes the gradient of the loss with respect to each model parameter.\n",
        "\n",
        "### 4Ô∏è‚É£ `optimizer.step()`\n",
        "\n",
        "* Uses those gradients to **update the parameters** (weights/biases).\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Example: Simple Regression with `torch.optim`\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Model\n",
        "model = nn.Linear(1, 1)   # y = wx + b\n",
        "\n",
        "# Loss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Dummy data\n",
        "x = torch.randn(10, 1)\n",
        "y = 3 * x + 2  # actual relation\n",
        "\n",
        "# Training\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()       # reset gradients\n",
        "    outputs = model(x)          # forward\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()             # backprop\n",
        "    optimizer.step()            # update weights\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° Common Optimizers in `torch.optim`\n",
        "\n",
        "| Optimizer  | Description                  | Key Parameters       | When to Use                            |\n",
        "| ---------- | ---------------------------- | -------------------- | -------------------------------------- |\n",
        "| `SGD`      | Stochastic Gradient Descent  | `lr`, `momentum`     | Simple and effective for small models  |\n",
        "| `Adam`     | Adaptive Moment Estimation   | `lr`, `betas`, `eps` | Default choice for deep learning       |\n",
        "| `RMSprop`  | Root Mean Square Propagation | `lr`, `alpha`, `eps` | Works well for RNNs                    |\n",
        "| `Adagrad`  | Adaptive Gradient            | `lr`, `eps`          | For sparse features                    |\n",
        "| `Adadelta` | Adaptive Delta               | `lr`, `rho`          | Variation of Adagrad                   |\n",
        "| `AdamW`    | Adam with weight decay       | `lr`, `weight_decay` | Modern standard (used in Transformers) |\n",
        "\n",
        "---\n",
        "\n",
        "## üî¨ Example Comparison: SGD vs Adam\n",
        "\n",
        "### Using SGD:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "```\n",
        "\n",
        "### Using Adam:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "```\n",
        "\n",
        "Both do the same job ‚Äî *update weights* ‚Äî but in different ways:\n",
        "\n",
        "* **SGD**: Same learning rate for all parameters.\n",
        "* **Adam**: Adaptive learning rate for each parameter based on momentum and variance.\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ Optional: Learning Rate Scheduling\n",
        "\n",
        "You can also adjust the learning rate dynamically using **schedulers**:\n",
        "\n",
        "```python\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "for epoch in range(30):\n",
        "    train()                # your training code\n",
        "    scheduler.step()       # reduce lr every 10 epochs\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Summary\n",
        "\n",
        "| Concept          | Description             | Example                                                |\n",
        "| ---------------- | ----------------------- | ------------------------------------------------------ |\n",
        "| Module           | Provides all optimizers | `torch.optim`                                          |\n",
        "| Create optimizer | Defines update rule     | `optimizer = optim.Adam(model.parameters(), lr=0.001)` |\n",
        "| Reset gradients  | Clears previous grads   | `optimizer.zero_grad()`                                |\n",
        "| Compute grads    | Backprop                | `loss.backward()`                                      |\n",
        "| Update weights   | Step forward            | `optimizer.step()`                                     |\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **In short:**\n",
        "\n",
        "> `torch.optim` is the engine that drives learning ‚Äî it takes the gradients from backpropagation and updates your model parameters intelligently.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Wk2taMDbYnbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuMZVJsvXHCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}