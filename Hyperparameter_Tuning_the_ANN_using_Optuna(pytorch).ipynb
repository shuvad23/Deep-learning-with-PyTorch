{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOuv/FQTu6W+P3uEhAJcM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuvad23/Deep-learning-with-PyTorch/blob/main/Hyperparameter_Tuning_the_ANN_using_Optuna(pytorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Hyperparameter tuning is the process of finding the best configuration of hyperparameters (the settings you choose before training a model) to maximize performance in machine learning and deep learning.\"\n",
        "\n",
        "üî• What Are Hyperparameters?\n",
        "- Hyperparameters are external settings that control how a model learns.\n",
        "They are not learned from data ‚Äî you pick them manually or let an algorithm search for the best ones.\n",
        "\n",
        "‚úÖ Examples in Machine Learning:\n",
        "\n",
        "  - Learning rate (Œ∑)\n",
        "\n",
        "  - Number of trees in Random Forest\n",
        "\n",
        "  - Maximum depth of a decision tree\n",
        "\n",
        "  - Number of neighbors (K) in KNN\n",
        "\n",
        "  - Regularization strength (C) in SVM or Logistic Regression\n",
        "\n",
        "‚úÖ Examples in Deep Learning:\n",
        "\n",
        "  - Learning rate\n",
        "\n",
        "  - Number of layers (depth)\n",
        "\n",
        "  - Number of neurons per layer\n",
        "\n",
        "  - Activation functions\n",
        "\n",
        "  - Batch size\n",
        "\n",
        "  - Dropout rate\n",
        "\n",
        "  - Optimizer (Adam, SGD, RMSprop, etc.)\n",
        "\n",
        "---\n",
        "\n",
        "üîß What Is Hyperparameter Tuning?\n",
        "\n",
        "- Hyperparameter tuning means:\n",
        "\n",
        "    - Trying different combinations of hyperparameters to find the one that gives the best accuracy, loss, or performance on validation data.\n",
        "\n",
        "  - It‚Äôs like adjusting the knobs of the model until it performs the best.\n",
        "\n",
        "\n",
        "üîç Why Is Hyperparameter Tuning Important?\n",
        "\n",
        "- Because wrong hyperparameters ‚Üí bad results, even if the model architecture is good.\n",
        "\n",
        "  - Good tuning can:\n",
        "\n",
        "  - Increase accuracy\n",
        "\n",
        "  - Reduce overfitting\n",
        "\n",
        "  - Speed up training\n",
        "\n",
        "  - Improve model stability"
      ],
      "metadata": {
        "id": "f01W0g7aaI_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß™ Common Hyperparameter Tuning Methods\n",
        "\n",
        "‚≠ê 1. Grid Search\n",
        "\n",
        "  - Try every possible combination.\n",
        "\n",
        "  - Pro: Finds best among listed options.\n",
        "\n",
        "  - Con: Very slow for large search spaces.\n",
        "\n",
        "‚≠ê 2. Random Search\n",
        "\n",
        "  - Randomly sample combinations.\n",
        "\n",
        "  - Pro: Much faster than grid search.\n",
        "\n",
        "  - Con: Might skip good combinations.\n",
        "\n",
        "‚≠ê 3. Bayesian Optimization\n",
        "\n",
        "  - Uses probabilities to choose the next best hyperparameters.\n",
        "\n",
        "  - Pro: Very efficient\n",
        "\n",
        "  - Con: Harder to implement\n",
        "\n",
        "‚≠ê 4. Hyperband / ASHA (Deep Learning)\n",
        "\n",
        "  - Early-stops bad models and saves training time.\n",
        "\n",
        "‚≠ê 5. Genetic Algorithms / Evolutionary Search\n",
        "\n",
        "  - Search based on mutation & selection."
      ],
      "metadata": {
        "id": "PRRPj0pzaKYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "üî• Hyperparameter Tuning an ANN Using Optuna (PyTorch Example)\n",
        "\n",
        "- Optuna is a state-of-the-art hyperparameter optimization framework.\n",
        "It automatically finds the best learning rate, hidden units, optimizer, dropout, etc."
      ],
      "metadata": {
        "id": "QHzAHL55aRPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step-by-Step Code: ANN + Optuna Tuning"
      ],
      "metadata": {
        "id": "QRL2mK_yzduc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrvHIa2Sxi7u"
      },
      "outputs": [],
      "source": [
        "#install optuna\n",
        "!pip install optuna==4.6.0\n",
        "!pip install sympy==1.12"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† 1. Build a Simple ANN Class"
      ],
      "metadata": {
        "id": "ma_aVB14z4MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import optuna"
      ],
      "metadata": {
        "id": "HNPb2KZdzx9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example dataset (dummy)\n",
        "x = torch.randn(1000,20) # 1000 samples, 20 features\n",
        "y = torch.randint(0,2,(1000,)) # 1000 binary labels"
      ],
      "metadata": {
        "id": "rhB4TUzM0PbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFMyVEZP0c1P",
        "outputId": "c8804d91-506a-4956-a50c-bc2619b8113c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX1_xLmF0jOY",
        "outputId": "682bfefc-cb64-4d36-abef-b824f6a1e1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3852, -0.2024,  0.6418,  ...,  0.5914,  0.9515, -1.0156],\n",
              "        [ 0.7890, -0.2004, -0.9029,  ...,  1.0663, -0.3850,  0.1282],\n",
              "        [ 0.4612,  0.0124, -0.2938,  ..., -0.2692, -0.2672,  0.0660],\n",
              "        ...,\n",
              "        [-0.1010,  1.3794,  0.9487,  ..., -0.4104,  0.3701,  0.7955],\n",
              "        [-0.8198, -0.3324,  0.8307,  ..., -0.7330, -0.8682,  1.4792],\n",
              "        [ 0.9425, -0.6863,  1.8670,  ...,  1.0880,  0.8200,  1.7518]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdNUFuej0kjx",
        "outputId": "c0833914-4bec-45e0-eb6b-193784f7c0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRmtUef40nHV",
        "outputId": "4125d154-d066-4c63-f71b-ff564b605bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "        1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "        1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "        1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "        1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
              "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "        0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "        1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "        1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "        0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "        0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "        1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "        0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "        1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(x,y)\n",
        "train_loader = DataLoader(dataset,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(dataset,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "PKjhYqQy02Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üèó 2. Define the ANN model"
      ],
      "metadata": {
        "id": "kANb2CRq1Hw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN(nn.Module):\n",
        "    def __init__(self,input_dim,hidden_dim,output_dim,dropout_rate):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim,hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_dim,output_dim)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "oNw4mLoo1Hfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3. The Optuna Objective Function\n",
        "\n",
        "- Optuna will:\n",
        "\n",
        "  - suggest learning rate\n",
        "\n",
        "  - suggest hidden units\n",
        "\n",
        "  - suggest dropout\n",
        "\n",
        "  - pick optimizer\n",
        "\n",
        "  - return accuracy"
      ],
      "metadata": {
        "id": "kz7d5S5v2N1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVED: This objective function is replaced by the more flexible one below.\n",
        "# def objective(trial):\n",
        "\n",
        "#     # hyperparameters to tune\n",
        "#     input = x.shape[1]\n",
        "#     output = 2  # Changed from 1 to 2 for binary classification with CrossEntropyLoss\n",
        "#     hidden_dim = trial.suggest_int('hidden_dim',16,256)\n",
        "#     dropout_rate = trial.suggest_float('dropout_rate',0.0,0.5)\n",
        "#     learning_rate = trial.suggest_float('learning_rate',1e-5,1e-1,log=True)\n",
        "#     batch_size = trial.suggest_categorical('batch_size',[32,64,128])\n",
        "#     optimizer_name = trial.suggest_categorical('optimizer',['Adam','RMSprop','SGD'])\n",
        "\n",
        "#     #Model\n",
        "#     model = ANN(input_dim=input,hidden_dim=hidden_dim,output_dim=output,dropout_rate=dropout_rate)\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     #optimizer\n",
        "#     optimizer = getattr(optim,optimizer_name)(model.parameters(),lr=learning_rate)\n",
        "\n",
        "#     # training loop(train 10 epoch)\n",
        "#     model.train()\n",
        "#     for epoch in range(10):\n",
        "#         for batch_idx,(data,target) in enumerate(train_loader):\n",
        "#             optimizer.zero_grad()\n",
        "#             preds = model(data)\n",
        "#             loss = criterion(preds,target)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#     # Evaluate accuracy\n",
        "#     model.eval()\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     with torch.no_grad():\n",
        "#         for data,target in test_loader:\n",
        "#             preds = model(data)\n",
        "#             predicted = preds.argmax(dim=1,keepdim=True)\n",
        "#             correct += (predicted == target.view_as(predicted)).sum().item()\n",
        "#             total += target.size(0)\n",
        "\n",
        "#     accuracy = correct/total\n",
        "#     return accuracy"
      ],
      "metadata": {
        "id": "R9YRfokx2UlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ 4. Run Optuna Study"
      ],
      "metadata": {
        "id": "bdx-xKms7DBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ 4. Run Optuna Study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective,n_trials=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M589VCvX7Bf7",
        "outputId": "170d4718-bd62-4063-d48b-a6540f45da7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-13 20:15:20,450] A new study created in memory with name: no-name-ec633a4e-1815-4888-af77-f531edfb0776\n",
            "[I 2025-12-13 20:15:21,111] Trial 0 finished with value: 0.576 and parameters: {'hidden_dim': 148, 'dropout_rate': 0.4964464565881205, 'learning_rate': 0.00020050410940550896, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.576.\n",
            "[I 2025-12-13 20:15:21,752] Trial 1 finished with value: 0.518 and parameters: {'hidden_dim': 151, 'dropout_rate': 0.4928859208300117, 'learning_rate': 1.2561779356883488e-05, 'batch_size': 64, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.576.\n",
            "[I 2025-12-13 20:15:22,238] Trial 2 finished with value: 0.568 and parameters: {'hidden_dim': 255, 'dropout_rate': 0.2318087242976828, 'learning_rate': 0.012738910186494258, 'batch_size': 32, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.576.\n",
            "[I 2025-12-13 20:15:22,737] Trial 3 finished with value: 0.506 and parameters: {'hidden_dim': 199, 'dropout_rate': 0.17784263391728494, 'learning_rate': 0.00024248369370839638, 'batch_size': 64, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.576.\n",
            "[I 2025-12-13 20:15:23,292] Trial 4 finished with value: 0.596 and parameters: {'hidden_dim': 92, 'dropout_rate': 0.4252770452770217, 'learning_rate': 0.00047675497247698606, 'batch_size': 32, 'optimizer': 'RMSprop'}. Best is trial 4 with value: 0.596.\n",
            "[I 2025-12-13 20:15:23,916] Trial 5 finished with value: 0.687 and parameters: {'hidden_dim': 171, 'dropout_rate': 0.49619017972974955, 'learning_rate': 0.003487599793398642, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.687.\n",
            "[I 2025-12-13 20:15:24,356] Trial 6 finished with value: 0.488 and parameters: {'hidden_dim': 83, 'dropout_rate': 0.20260948504850995, 'learning_rate': 0.0005334847616953258, 'batch_size': 128, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.687.\n",
            "[I 2025-12-13 20:15:24,919] Trial 7 finished with value: 0.716 and parameters: {'hidden_dim': 228, 'dropout_rate': 0.030634726487279884, 'learning_rate': 0.003133588336507262, 'batch_size': 32, 'optimizer': 'RMSprop'}. Best is trial 7 with value: 0.716.\n",
            "[I 2025-12-13 20:15:25,380] Trial 8 finished with value: 0.595 and parameters: {'hidden_dim': 122, 'dropout_rate': 0.22377796774919828, 'learning_rate': 0.02084801801239791, 'batch_size': 32, 'optimizer': 'SGD'}. Best is trial 7 with value: 0.716.\n",
            "[I 2025-12-13 20:15:25,897] Trial 9 finished with value: 0.578 and parameters: {'hidden_dim': 52, 'dropout_rate': 0.3582236831729338, 'learning_rate': 0.00023334789187998261, 'batch_size': 32, 'optimizer': 'RMSprop'}. Best is trial 7 with value: 0.716.\n",
            "[I 2025-12-13 20:15:26,505] Trial 10 finished with value: 0.656 and parameters: {'hidden_dim': 251, 'dropout_rate': 0.01911125887903974, 'learning_rate': 0.05219313007835591, 'batch_size': 32, 'optimizer': 'RMSprop'}. Best is trial 7 with value: 0.716.\n",
            "[I 2025-12-13 20:15:27,117] Trial 11 finished with value: 0.74 and parameters: {'hidden_dim': 197, 'dropout_rate': 0.02315097355344744, 'learning_rate': 0.006754045034977246, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 11 with value: 0.74.\n",
            "[I 2025-12-13 20:15:27,776] Trial 12 finished with value: 0.741 and parameters: {'hidden_dim': 208, 'dropout_rate': 0.004918961334206322, 'learning_rate': 0.0029985478490724806, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.741.\n",
            "[I 2025-12-13 20:15:28,422] Trial 13 finished with value: 0.762 and parameters: {'hidden_dim': 193, 'dropout_rate': 0.10529330995375707, 'learning_rate': 0.0026656472362355187, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 13 with value: 0.762.\n",
            "[I 2025-12-13 20:15:29,064] Trial 14 finished with value: 0.723 and parameters: {'hidden_dim': 198, 'dropout_rate': 0.0987739554729703, 'learning_rate': 0.0015847460371742944, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 13 with value: 0.762.\n",
            "[I 2025-12-13 20:15:29,786] Trial 15 finished with value: 0.534 and parameters: {'hidden_dim': 220, 'dropout_rate': 0.10046082413880236, 'learning_rate': 4.7612094791720884e-05, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 13 with value: 0.762.\n",
            "[I 2025-12-13 20:15:30,681] Trial 16 finished with value: 0.59 and parameters: {'hidden_dim': 174, 'dropout_rate': 0.11569544635987433, 'learning_rate': 0.09514253526849654, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 13 with value: 0.762.\n",
            "[I 2025-12-13 20:15:31,484] Trial 17 finished with value: 0.586 and parameters: {'hidden_dim': 24, 'dropout_rate': 0.30441902920475167, 'learning_rate': 0.0012124810451224835, 'batch_size': 64, 'optimizer': 'Adam'}. Best is trial 13 with value: 0.762.\n",
            "[I 2025-12-13 20:15:32,420] Trial 18 finished with value: 0.729 and parameters: {'hidden_dim': 125, 'dropout_rate': 0.14758558819239972, 'learning_rate': 0.026054821060381546, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 13 with value: 0.762.\n",
            "[I 2025-12-13 20:15:33,209] Trial 19 finished with value: 0.762 and parameters: {'hidden_dim': 223, 'dropout_rate': 0.07032633852364945, 'learning_rate': 0.005402930198801358, 'batch_size': 128, 'optimizer': 'Adam'}. Best is trial 13 with value: 0.762.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üèÜ 5. Print Best Hyperparameters"
      ],
      "metadata": {
        "id": "4Ux18Abg7Yvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üèÜ 5. Print Best Hyperparameters\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "for idx,(key, value) in enumerate(study.best_params.items()):\n",
        "    print(f\"\\t{idx+1}- {key}: {value}\")\n",
        "print(\"Best Accuracy:\",study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woKvmgL47Yd9",
        "outputId": "70578d38-2893-4c7d-e1ab-fa40a0021181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'hidden_dim': 193, 'dropout_rate': 0.10529330995375707, 'learning_rate': 0.0026656472362355187, 'batch_size': 128, 'optimizer': 'Adam'}\n",
            "\t1- hidden_dim: 193\n",
            "\t2- dropout_rate: 0.10529330995375707\n",
            "\t3- learning_rate: 0.0026656472362355187\n",
            "\t4- batch_size: 128\n",
            "\t5- optimizer: Adam\n",
            "Best Accuracy: 0.762\n"
          ]
        }
      ]
    }
  ]
}